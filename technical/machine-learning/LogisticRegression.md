# 机器学习
## 逻辑回归

> 房雷 864720655@qq.com/fanglei@pku.edu.cn
> 2017-05-15
> 

#### 线性回归

考虑二分类任务，其标记输出为 $y \in \{0, 1\}$,以对数几率函数（一种Sigmoid函数）施加在线性回归上，得到
$$
	y = \frac{1}{1 + e^{-(w^T x + b)}}
$$
$$
	\ln\frac{y}{1-y}=w^T x + b
$$
若将 $y$ 视为样本 $x$作为正例的可能性，则 $1-y$是反例的可能性，两者比值
$$
\frac{y}{1-y}
$$
称为**几率**，反映了 $x$作为正例的相对可能性。

##### 特点
1. 直接对分类可能性进行建模，无需事先假设数据分布，避免假设分布不准确所带来的问题；
2. 不仅预测“类别“，还得到近似概率预测，对许多需利用概率辅助决策的任务很有用；
3. 对率函数是任意阶次可导的凸函数，有很好的的数学性质，许多数值优化算法都可以直接用于求取最优解。

##### 求解
将 $y$ 视为类后验概率估计 $p(y=1|x)$，则
$$
p(y = 1 | x) = \frac{ e^{-(w^T x + b)}}{1 + e^{-(w^T x + b)}}
$$
$$
p(y = 0 | x) = \frac{ 1 }{1 + e^{-(w^T x + b)}}
$$
可采用极大似然估计方法来估计参数 $w$ 和 $b$。最后得到的似然函数可通过经典的数值优化算法如梯度下降法、牛顿法求解。

